======
Issues
======

Populate this list with desired fuctionality and similar and other todo items.
Bugs go in a separate list: BugList. For longer descriptions of issues (which
go in a separate page), the following fields might be useful: date, commit,
submitter, owner, status (open, closed, inprogress, etc).

Client/server architecture
--------------------------

- add a mechanism for dealing with multiple requests - add 'busy' reply in
  server. This requires a threaded server.
- MultipleParallelSimulations (low priority)
- add support for specifying current stimulus in server mode (to run on server)

Network specification/DSL
-------------------------

- EfficientNetworkConstruction
- make excitatory/inhibitory a property of the neuron
- add support for arbitrary user-specified neuron properties
- interpret script rather than compile it.

Simulation general
------------------

- report error for unknown command-line options

CUDA backend
------------

- If the GPU is in use by some other process or user the kernel blocks. We
  should provide a warning or similar.
- It's now possible to overflow the firing buffer in L0 delivery, if more than
  half the neurons fire. We can avoid this by flushing the buffer whenever it's
  half-full and making it a rotating buffer.
- For cycle counting, we only report data for thread block 0. Get data from all
  and report mean and std. deviation. 
- Extend max delay to 64, at least when STDP is enabled. The history needs to
  be long enough to hold delay+dt.
- Modify mapper to reduce number of sequential loads in L0 delivery. This is a
  small saving, perhaps 5%.
- In the STDP pruning step we traverse the entire forward matrix. We can speed
  this up by recording what source neurons have modified synapses. The overall
  cost of this step is nearly 10% of execution time for smallworld network with
  STDP applications every 50ms.
- For L1 spike queue, use per-partition configuration of max synapses
- For L1 spike queue, ensure that we don't deliver garbage results. We need to
  clear unused entries. This is best done by writing for all threads in a warp,
  setting value to 0 if not used. Add smallworld unit test to check this.
- When loading synapses, limit the loads on a per-neuron basis, rather than
  using a global maximum. Cache the maximum values, as these are fixed for the
  network.
- instead of requiring caller to do a separate configuration step, gather stats
  when setting up network data structures, and perform configuration when
  writing it all to the device. This is done for L0 CM. Do the same for L1 and
  for partition sizing.
- Parallel loading of incoming L1 spikes 
- StoreExplicitFiringIndices
- Simple code issues: add address macros CLUSTER, NEURON; replace
  reinterpret_cast with __float_as_int
- allow the c parameter to be hard-coded. Often this will be fixed at -65.0.
- consider removing sorting from server again.
- The firing buffer read (device->host) could be improved. In the average case
  it should be possible to do just a single read containing both the buffer
  headers and the data, where the read size is based on an estimate of the
  firing rate. This could even be adapted dynamically.
- It should be possible to recover from a firing output buffer overflow. The
  device needs to be able to detect the overflow, though, and then just stop
  writing.
- If we use a very large amount of memory the CUDA backend will fail with a
  non-descript error (in SMatrix ctor), produce some sensible error message
- Add reporting of memory usage

Haskell core
------------

- add simulation monad. It should be possible to draw upon random numbers 
- improve the reporting of failed tests. If we compare two networks and they
  somehow differ we'll get an enourmous dump which is next-to-impossible to make
  sense of. Do a recursive descent keeping track of the current context.
- the 'client' backend does not support request for weight matrix. Add this.
- the 'cpu' backend does not support request for weight matrix. Add this.
- make sure we correctly compute the max buffer size in allocRT. Currently this
  is just set to a large number. Should determine how many synapses cross
  partition bounadry. It would make sense to only allocate this after CM has
  loaded.
- configure max L0 connections correctly. This is currently set based on global
  maximum.
- merge duplicate L1 synapse. If we make sure the network is constructed such
  that synapses with the same source and target end up in the same slot, this
  should be simple.
- remove print method from Axon.hs. Make use of show instead. May need to add
  Source field to Axon in order to get a complete listing.
- add/complete time function in NSim 

MatlabAPI
---------

- add support for thalamic input in the matlab interface
- add support for per-synapse specification of STDP

Build system
------------

- Make cabal build invoke cuda build process

- in Makefile, have cuda build check configuration in dist to determine whether
  or not to build the kernel library
- add creation of windows install (MSI), possibly using Bamse (from hackage)
- add creation of deb installer
- tie the test framwork into git. require all tests to pass.
- cmake? We should do some configuration to determine if CUDA is present
- add tarballing to the build script
- tie CUDA and MEX builds into the cabal build
- use a 'client-dist' directory on the local machine 

CPU backend
-----------

- make this a lot faster! We should use multiple cores. SSE might also be an idea.
